
# Load Data

```{r, echo=TRUE}

library(caret)
library(arm)
library(abind)
library(kernlab)
library(klaR)
library(rattle)
library(randomForest)
library(rpart)
library(nnet)
library(caTools)
library(rpart.plot)
library(RColorBrewer)
library(rattle)

set.seed(12345)

```

#Data Importing into R
Setting train and testing datasetsâ€™ urls:

```{r, echo=TRUE}
csvTrain <- "pml-training.csv"
train <- read.csv(csvTrain, na.strings=c("NA","#DIV/0!",""))

csvTest <-  "pml-testing.csv"
test <- read.csv(csvTest, na.strings=c("NA","#DIV/0!",""))
```
```{r, echo=TRUE, eval=FALSE}

summary(train)
summary(test)
```

Particioning

```{r, echo=TRUE}
inTrain <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
myTraining <- train[inTrain, ]; myTesting <- train[-inTrain, ]
dim(myTraining); dim(myTesting)
```

#Data Cleansing

Clean the high set of NAs and Low variance data

```{r, echo=TRUE}
nearzero <- nearZeroVar(myTraining, saveMetrics = TRUE)
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[, !myNZVvars]
dim(myTraining)
```


Variables related to id, 
```{r, echo=TRUE}
myTraining <- myTraining[c(-1)]
```




Clean Variables with NAs and more than 60% variance
```{r, echo=TRUE}

trainingV3 <- myTraining 
for(i in 1:length(myTraining)) { 
        if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { 
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { 
                trainingV3 <- trainingV3[ , -j] 
            }   
        } 
    }
}

dim(trainingV3)

myTraining <- trainingV3
rm(trainingV3)
```

#Set test dataset

TrainControl is used to perform 7-fold cross validation to avoid overfitting and out of sample error

```{r, echo=TRUE}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) 
myTesting <- myTesting[clean1]
testing <- test[clean2]

dim(myTesting)
dim(testing)

```

Coerse the dataset into the same type for test and training dataset

```{r, echo=TRUE}
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}
#And to make sure Coertion really worked, simple smart ass technique:
testing <- rbind(myTraining[2, -58] , testing) #note row 2 does not mean anything, this will be removed right.. now:
testing <- testing[-1,]
```

Build the   Prediction Model: Decision Tree
```{r, echo=TRUE}
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
```

Predicting

```{r, echo=TRUE}
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
```

test restult with Confusion matrix
```{r, echo=TRUE}

confusionMatrix(predictionsA1, myTesting$classe)
```

Build the   Prediction Model: Random Forest

```{r, echo=TRUE}
modFitB1 <- randomForest(classe ~. , data=myTraining)
```

Predictiong Sample Error

```{r, echo=TRUE}
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
```

```{r, echo=TRUE}

confusionMatrix(predictionsB1, myTesting$classe)
```

Random Forests yielded better Results, as expected!!

# Genetaring the files to submit the result

```{r, echo=TRUE}

predictionsB2 <- predict(modFitB1, testing, type = "class")


pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB2)

```
